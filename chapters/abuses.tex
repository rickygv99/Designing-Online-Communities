\documentclass[class=book, crop=false]{standalone}

%% Image paths
\usepackage{graphicx}
\graphicspath{{images/}}

\usepackage{wrapfig}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{csquotes}

%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

%% Sets epigraph style
\usepackage{epigraph}
\setlength\epigraphwidth{.8\textwidth}
\setlength\epigraphrule{0pt}

%% Sets line style
\linespread{1.3}

%% Key term command
\usepackage{marginnote}
\providecommand{\keyterm}[1]{\textbf{#1}\marginnote{\scriptsize \textbf{#1}}}

\begin{document}

\epigraph{\itshape “Anyone can speak Troll. All you have to do is point and grunt.”}{---J.K. Rowling, \textit{Harry Potter and the Goblet of Fire}}

\epigraph{\itshape "Don't feed the trolls!"}{---\textit{The Internet}}

Most members of online communities are well-meaning people who wish to positively engage with others in their communities. However, sometimes malicious users join online communities with the intent of harassing others. Many of these users are relatively harmless and their bad actions typically consist of deliberately annoying other users. These users are colloquially known as \keyterm{trolls}, and we call this act of intentionally disrupting online communities \textit{trolling} [Schwartz 2008].

In the early days of the Internet, trolling was relatively harmless. Trolls posted dumb questions in \keyterm{Usenet}\footnote{Usenet was invented in 1980 and was pretty similar to the online forums of today. A lot of the Internet’s slang comes from Usenet, including commonplace terms such as “FAQ,” “flame,” and “spam”.} newsgroups in order to see who would take the bait and reply [Schwartz 2008]. Many trolls are ignored by users; however, trolling is disruptive and deserves attention. Trolling also has a darker side, which we will explore extensively in this chapter. It seems wrong to call these users trolls -- they are \textit{abusers} and should be labeled as such. Some of these abusers attempt to drive others off the Internet through targeted attacks, often directed at minority groups. Some abusers blackmail children into sending them nude photos, driving many children to take their own lives. Some abusers report fake hostage situations at others' houses, leading SWAT teams to show up, with sometimes fatal consequences.

Online harassment is not a minor problem, nor should it be taken lightly. 41\% of Americans have been the victim of online harassment. A disproportionate number of victims are minorities. One in four African Americans are racially targeted online as opposed to only one in thirty-three white Americans. Two women for every man are harassed online because of their sex. [Duggan 2017]\\

Citron, D. (2014). Hate crimes in cyberspace. Cambridge, MA: Harvard University Press\\
 * Harassment is a civil rights issue about the capacity for people to participate in public spaces.

Lenhart, Amanda et al. 2016. "Online Harassment, Digital Abuse, and Cyberstalking in America." (2016).\\
 * Argues that "online harassment is defined less by the specific behavior than its intended effect on and the way it is experienced by its target."

\textbf{----------------------------------------}

\textbf{CONTENT WARNING}

\textbf{----------------------------------------}

Many examples in this chapter describe real-world cases of hate speech, suicide, self-harm, sexual assault and sexual harassment. If this material might trigger you, I encourage you to take a break from reading or to skip this chapter entirely. Whereas feeling uncomfortable is important for growth, this is different from experiencing symptoms of PTSD and STSD.

\section{Trolling}

Jhaver, Shagun et al. 2018. "The View from the Other Side: The Border Between Controversial Speech and Harassment on Kotaku in Action." First Monday 23, 2 (2018).\\
 * "Individuals often have more complex views than stereotypes predict," and it is important to differentiate sincere misunderstanding from deliberate attacks.

Boyd, Danah. 2008. Why Youth Heart Social Network Sites: The Role of Networked Publics in Teenage Social Life. MacArthur Foundation Series on Digital Learning -- Youth, Identity, and Digital Media (2008), 119-142.\\
 * Identified four properties of SNSs that fundamentally alter social dynamics of harassment and amplify its effects online: persistence, searchability, replicability, and invisible audiences.

Citron, Danielle Keats. 2014. Hate crimes in cyberspace. Harvard University Press.\\
 * Search engines index content on web and harassers can put indexed abusive posts to malicious use years after they first appear.\\
 * "There are speech interests beyond that of the harassers to consider." Online harassment often results in silencing of harassed users and therefore impinges upon their freedom of expression.

\subsection{Gendertrolling}

\keyterm{Gendertrolling}\index{gendertrolling} is a very nefarious type of trolling targeted at women online. Unlike other online trolls, who troll mostly for fun, gendertrolls have a very specific purpose: to drive women out of online communities. Because it is so targeted and purpose-driven, it is difficult to overcome; unlike traditional trolling, it cannot be overcome by "not feeding the trolls". Gendertrolling is distinct for its overtly objectifying and sexualizing attacks, its ability to sustain attacks for months or even years, its ability to target users across multiple online platforms and its frequent use of rape and death threats. [Mantilla 2015]

One particularly notable case of gendertrolling was the 2014 \keyterm{Gamergate}\index{Gamergate} controversy. Game developer Zoe Quinn's ex-boyfriend Eron Gjoni posted personal information about her and their relationship online, prompting gendertrolls to harass her. Some online users attempted to reframe the incident as exposing corruption in video game journalism because Quinn was alleged to have dated a video games journalist. However, this reframing was quickly shown to be the result of misinformation spread by gendertrolls because the journalist in question had never written about Quinn. Furthermore, this attempt to delegitimize Quinn because of her past relationships is a frequent method used by gendertrolls to drive women offline. Gamergate quickly spread beyond just Quinn; other women in the video game industry were subsequently attacked as well, including game developer Brianna Wu and video game critic Anita Sarkeesian. [Mantilla 2015]

https://www.aaai.org/ocs/index.php/ICWSM/ICWSM11/paper/viewFile/2873/4398\\

https://www.nytimes.com/2018/08/08/technology/personaltech/internet-trolls-comments.html


\section{Cyberbullying}

\keyterm{Cyberbullying} is more nefarious than trolling -- unlike trolling, it is targeted for a particular purpose [Lenhardt 2013] and abusers might follow their victim across the Internet. Abusers might use personal attacks or share personal information about their victims.

Women and members of the LGBTQ+ community are more likely to be victims of cyberbullying and perpetrators are more likely to be male [Aboujaoude et al. 2015].

Cyberbullying can have fatal real life consequences. Victims of cyberbullying have higher rates of suicide ideation and a greater probability of committing suicide [Hinduja and Patchin 2010].

\subsection{Dogpiling}

\section{Hate speech}

The concept of hate speech is controversial in today's political climate. What defines hate speech? Nobody really has an agreed-upon definition of hate speech nor an agreed-upon idea of where the line is between hate speech and accepted speech. Many online social platforms ban hate speech; however, they too tend to have very vague definitions of hate speech. Take a look at Facebook's Community Standards for instance, which states:

\begin{displayquote}
We define hate speech as a direct attack on people based on what we call protected characteristics -- race, ethnicity, national origin, religious affiliation, sexual orientation, caste, sex, gender, gender identity, and serious disease or disability. ... We define attack as violent or dehumanizing speech, statements of inferiority, or calls for exclusion or segregation. [Facebook 2019]
\end{displayquote}

But what does "direct" mean in the term "direct attack"? What counts as "statements of inferiority"? Later in their Community Standards, Facebook further says "We allow humor and social commentary related to these topics." But who determines what is humorous? How can one determine intent? This vagueness is frustrating for some; however, one can see why Facebook might appreciate the vagueness -- it lets Facebook have a bit of leeway in deciding what counts as hate speech.

This vagueness has led political figures, typically conservatives, to accuse Facebook of biasing against them. In 2019, Facebook banned several extremist users including white nationalist Paul Nehlen, inflammatory conservative pundit Milo Yiannopoulos and conspiracy theory-peddling Infowars head Alex Jones, who is known for arguing that child victims of the Sandy Hook school shooting were paid actors. The ban led prominent conservative politicians, including President Trump, Newt Gingrich and Ted Cruz, to slam Facebook for alleged bias against conservatives. [Coaston 2019] While Facebook was certainly justified in banning these individuals, the vagueness of its hate speech policies makes its moderation process feel like a black box, one which may seem arbitrary to some.

In light of the vagueness of the term "hate speech," a team of researchers working for the Dangerous Speech Project is attempting to create a new term called "Dangerous Speech," which is defined as:

\begin{displayquote}
Any form of expression (e.g. speech, text, or images) that can increase the risk that its audience will condone or commit violence against members of another group. [Benesch et al. 2019]
\end{displayquote}

The researchers further explain what dangerous speech is: it causes its target audience, the "in-group, to become afraid of another group, the "out-group". It is usually false and harms \textit{indirectly} -- the speaker is not committing violence themselves but rather increasing the risk that the audience will do so. [Benesch et al. 2019]

The researchers found that there are five common characteristics of dangerous speech:
\begin{enumerate}
    \item \textbf{Dehumanization}: The speaker encourages the audience to view the out-group as less than human. For example, common images invoked of the out-group include animals, insects, diseases, beasts, demons, and natural disasters.
    \item \textbf{Accusation in a Mirror}: The speaker accuses (often falsely) the out-group of committing the same horrible actions that the speaker wants the in-group to commit. This provides the speaker with justification for the in-groups actions -- "it's us or them".
    \item \textbf{Threat to Group Integrity or Purity}: The speaker proclaims that the out-group is ruining the in-group, whether by changing the in-group's culture, hampering the in-group's efforts, or just generally making life harder for the in-group.
    \item \textbf{Assertion of Attack Against Women and Girls}: The speaker accuses the out-group of threatening or violating women and girls in the in-group.
    \item \textbf{Questioning In-Group Loyalty}: The speaker accuses certain members of the in-group of not supporting the in-group's cause well or even of siding with the out-group.
\end{enumerate}

\subsection{Anti-Semitism}

Anti-Semitism is frequent on the Internet. Alt-right website \textit{The Daily Stormer} is known for targeting Jewish individuals online. Founder and neo-Nazi Andrew Anglin (who previously founded a website called \textit{Total Fascism}), said in a 2014 biographical post, "I ask myself what Hitler would do if he'd been born in 1984 in America and was dealing with this situation we are currently dealing with and also really liked 4chan and Anime." The home page of the site has sections such as "Jewish Problem" and "Race War". The headline of an example article on the website on April 27, 2014 read "SPLC is Suing Anglin! Donate Now to STOP THESE KIKES." [Carson 2017]

The American Defamation League (ADL) issued a report in 2016 confirming the targeting of Jewish journalists during the 2016 US presidential campaign. According to the report, at least 800 journalists were the target of anti-Semitic tweets during the campaign, with just ten Jewish journalists receiving 83\% of the anti-Semtic tweets. Many of the anti-Semitic tweets came from right-wing or conservative Twitter accounts, with the most frequent words in the accounts' bios being "Trump", "nationalist", "conservative", "American", and "white". [ADL 2016]

\section{Doxing}

Another common type of online antisocial behavior is \keyterm{doxing}\index{doxing} (also called doxxing and d0xing), which is when a user publicizes personal information about another user online against their will. This action is particularly damaging because it is practically irrevocable -- once information is posted on the Internet, it cannot be easily deleted.

In 2016, philosopher David Douglas identified three types of doxing: deanonymizing doxing, targeting doxing and delegitimizing doxing. [Douglas 2016]

\keyterm{Deanonymizing doxing}\index{doxing!deanonymizing doxing} is when a user identifies an anonymous online user by their real-world identity.

\keyterm{Targeting doxing}\index{doxing!targeting doxing} is when a user releases another user's private information online. 

\keyterm{Delegitmizing doxing}\index{doxing!delegimitizing doxing} is when a user spreads embarrassing or damaging information about another user online in order to discredit them. It is frequently used in tandem with targeting doxing but differs from targeting doxing in that its primary motive is to discredit other users rather than to harass them. For example, disgruntled exes sometimes spread 'revenge porn' online, which are explicit photographs of their former lovers spread without their consent. However, while delegitimizing doxing is frequently used nefariously, it can also be used to expose wrongdoings by public figures and government officials. For example, a group of online users in China, called the "human flesh search engine" by the Chinese media, work to publicize corruption by Chinese officials in order to oust them [Gao and Stanyer 2013].

\section{Disinformation}

Whereas doxing concerns spreading personal or damaging information about others online, disinformation campaigns involve spreading false information about victims in order to spin up controversy about them and bring others to harass them. While most people think of political agendas, especially in the context of the 2016 and 2018 U.S. presidential elections, when they think of disinformation, disinformation is also frequently used to target and discredit individuals.

For example, on January 20, 2017, YouTube account "My Name is Conservative" posted a video of an anti-Trump protester lighting a Trump supporter's hair on fire during a protest on Trump's inauguration day. Right-wing site WeSearchr posted a bounty to find out who the anti-Trump protester was in the video. On January 25, right-wing site "Fellowship of the Minds" broke down the video into individual frames and concluded that Norma Zahory, a Maryland woman, was the perpetrator. The site then proceeded to dox Zahory, posting the address, phone number, email address, name of the CEO, and supporting companies of the nonprofit which Zahory worked at. [Collins 2017]

The Daily Caller, a conservative news site, picked up the story, causing Zahory's case to hit mainstream media. Zahory was inundated with calls for her deportation (she was Afghani-American and alt-right commentators likely mistook her for Hispanic). [Collins 2017]

However, Zahory was innocent. The Daily Caller published a follow-up article explicitly stating "There's a superficial resemblance at best. Norma Zahory did not do this. Leave her alone." [Treacher 2017]. "There were all these usernames attacking me, my character. I kept saying I didn't do it. I was asking myself, 'Why do all of these people hate me based on the little info they have?" Zahory said. [Collins 2017]

Sometimes disinformation takes the form of hacking someone's social media account and creating fake profiles. This happened to one Afghani woman in 2015. A hacker had broken into her Facebook page and covered her timeline with posts discussing drug use and other illegal actions. In the United States, this might be seen as an annoyance at best; however, in Afghanistan, this can lead to death. Internet cafe owner Farid Ahmadi, who often encounters women desperate for help after being hacked, said that even if the fake account is reported to Facebook, "Most of the time, Facebook is saying, 'No, you're wrong, thanks for reporting, but this is not a fake account.' I don't think they understand the culture of Muslim countries." [Holley 2015]

\section{Swatting}

Swatting is one example of how online hate can cross into the real world. Swatting is when an online troll places a fake 911 call alleging that there is a hostage situation at the house of someone they are victimizing. A hostage situation requires a lot of heavily armed law enforcement officers or even a SWAT team to show up and, in the pretense of a hostage situation, tensions are high. This can cause law enforcement officers to accidentally shoot the victim -- trolling can have fatal consequences.

\begin{wrapfigure}{r}{0.4\textwidth} %this figure will be at the right
    \centering
    \includegraphics[width=0.4\textwidth]{FBI}
    \caption{FBI doing a practice drill}
\end{wrapfigure}

For example, in December of 2017, California man Tyler Barriss was asked by a gamer to place a fake 911 call at the address of 28-year old Kansas man Andrew Finch, who was playing online game "Call of Duty" with the gamer. Barriss placed the phone call, pretending that he was Finch and stating that he had shot his father, had the rest of his family hostage, and was prepared to burn his house down with his family inside it. Barriss used a technique called "spoofing" to make it seem as if the call was sent from inside Finch's house. When law enforcement arrived, Finch answered the door and an officer accidentally shot and killed him. Barriss was ultimately convicted and sentenced to twenty years in prison. [Andone 2019]

Even if the victim isn't shot, the experience is traumatic. Law enforcement officers break into the victim's house and physically subdue the victim, taking them into police custody, sometimes in full view of their neighbors.

Despite the devastating consequences of swatting, it is often difficult to prosecute swatting cases because fake 911 calls are typically placed as a joke, often by minors. Since minors are often unaware of the consequences of swatting, it is difficult for prosecutors to prove that the minors meant to cause harm. [Andone 2019] There are some cases were swatting perpetrators are sentenced, as in the case of Barriss. However, until recently, there was no federal law specifically outlawing swatting.

\section{Sextortion}

Sexual extortion, colloquially known as sextortion, is when malicious actors blackmail victims by claiming that they have pictures or videos of the victims performing sexual acts and requesting either money or more explicit photos and videos if the victims don't want the sexually explicit material made public. Sextortion is illegal [FBI 2019] and typically has a devastating effect on its victims, who have reported feeling like they were trapped in "sexual slavery" and were left as "a hollow shell" [Jacobo and Weinstein 2016].

One way sextortion frequently occurs is when a malicious actor becomes friendly with the victim and requests nude photos or videos. Once the malicious actor receives the explicit material, then they demand more recordings of sexual acts in exchange for keeping the nude photos private. For example, in one case, a 46-year old Indiana man named Richard Finkbiner created fake attractive profiles on social media platforms (a deceptive practice commonly known as "catfishing") and tricked minors into sending him sexually explicit pictures and videos [FBI 2019].

Sextortion can also occur without an exchange of nude photos ever taking place. Scammers often send messages to victims claiming that they have photos or videos of the victim engaging in sexual activities or viewing inappropriate content. If the victim doesn't send the scammer either money or more explicit material, then the scammers threaten that they will send the photos to the victim's friends.

Sextortion is often deadly, with a 2015 FBI report finding that, out of a random sample of 43 sextortion cases, in over 28\% of the cases, the victim attempted or committed suicide [Jurecic et al. 2016]. Furthermore, sextortion is very prevalent. Between 2015 and 2018, the National Center for Missing and Exploited Children (NCMEC) received over 5,017 reports of sextortion of minors through their CyberTipline [FBI 2019]. According to Brian Herrick, an Assistant Section Chief at the FBI, "Sextortion is a global threat, so children are being victimized 24 hours a day" [FBI 2019].

It is important to note that in a research study conducted by the Brookings Institute, out of a random sample of 78 prosecuted sextortion cases, all the perpetrators were male [Jacobo and Weinstein 2016]. According to a study by the Brookings Institute, "71 percent of the cases we examined involved only victims under the age of 18". The US Department of Justice states that "sextortion is by far the most significantly growing threat to children" [Jacobo and Weinstein 2016]. The victims in sextortion cases are typically young women [Jacobo and Weinstien 2016]. Furthermore, in more than half of sextortion cases, the victim or victims knew the perpetrator beforehand [Segall 2016].

\section{Revenge porn}

Many lovers send each other nude photos over social media or messaging platforms, a practice known as "sexting". If a particularly nasty break-up happens, the former lovers have nude photographs of the other at their disposal. Sometimes an angry ex-lover might want to take revenge on their ex for breaking up at them and decide to release their ex's nude photographs on the Internet or send them to their ex's friends, a malicious action known as "revenge porn".

In the United States, 46 out of the 50 states, Washington DC and Guam all have laws illegalizing revenge porn. [Cyber Civil Rights Initiative]

\section{Reading questions}

\section{Solutions to reading questions}

\section{Bibliography}

Andone, Dakin. "Swatting is a dangerous prank with potentially deadly consequences. Here's what you need to know." CNN. March 30, 2019. Web.

Benesch, Susan et al. "Dangerous Speech: A Practical Guide." Dangerous Speech Project. 2019.

Carson, Erin. "This lawsuit could shut internet Nazis down." Cnet. November 27, 2017. Web.

Coaston, Jane. "The Facebook free speech battle, explained." Vox. May 14, 2019. Web.

Collins, Terry. "Here's the brutal reality of online hate." Cnet. November 27, 2017. Web.

Douglas, David M. "Doxing: a conceptual analysis." Ethics and Information Technology 18 (3): pp. 199-210. June 28, 2016.

Duggan, Maeve. “Online Harassment 2017.” \textit{Pew Research Center}. July 11, 2017. Web.

Facebook. "Community Standards." 2019.

Gao, Li and Stanyer, James. "Hunting corrupt officials online: the human flesh search engine and the search for justice in China." Information, Communication \& Society 17 (7): pp. 814-829. September 12, 2013.

Holley, Peter. "Afghan women say hackers and threats have made them afraid of Facebook." The Washington Post. September 18, 2015. Web.

Jacobo, Julia and Weinstein, Janet. "Social Media Manipulation is Most Common Form of Sextortion, Study Finds." ABC News. May 11, 2016. Web.

Jurecic, Quinta et al. "Sextortion: The problem and solutions." Brookings Tech Tank. May 11, 2016. Web.

Mantilla, Karla. \textit{Gendertrolling: How misogyny went viral}. Santa Barbara, CA: Praeger. 2015.

Schwartz, Mattathias. "The Trolls Among Us." \textit{The New York Times Magazine}. August 3, 2008. Web.

Segall, Laurie. "A disturbing look inside the world of sextortion." CNN Business. June 23, 2016. Web.

Treacher, Jim. "The Woman Who Set A Trump Supporter's Hair On Fire Is Still Unidentified." The Daily Caller. January 24, 2017. Web.

ADL. "Anti-Semitic Targeting of Journalists During the 2016 Presidential Campaign: A report from ADL's Task Force on Harassment and Journalist." October 19, 2016. Web.

Federal Bureau of Investigation, U.S. Department of Justice. "Sextortion: Recognize, Prevent, Protect." September, 2019. Web.

Cyber Civil Rights Initiative. "46 States + DC + One Territory Now Have Revenge Porn Laws." Web.

\section{Image credits}

Picture of FBI doing a practice drill. By U.S. Army Materiel Command - Flickr, CC BY 2.0, https://commons.wikimedia.org/w/index.php?curid=45245371

\end{document}
