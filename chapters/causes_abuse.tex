\documentclass[class=book, crop=false]{standalone}

%% Image paths
\usepackage{graphicx}
\graphicspath{{images/}}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{csquotes}

%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

%% Sets epigraph style
\usepackage{epigraph}
\setlength\epigraphwidth{.8\textwidth}
\setlength\epigraphrule{0pt}

%% Sets line style
\linespread{1.3}

%% Key term command
\usepackage{marginnote}
\providecommand{\keyterm}[1]{\textbf{#1}\marginnote{\scriptsize \textbf{#1}}}

\begin{document}

\section{The online disinhibition effect}

Psychology professor John Suler observed that people tend to act out more and reveal more online than they would in real life, a behavior he called the \keyterm{online disinhibition effect}\index{online disinhibition effect}. [Suler 2004] Adolescents in particular are more willing to reveal information online [Yang, Yang and Chiou 2010; Barket-Bojmel and Shahar 2011]. The online disinhibition effect isn’t just negative; it can have positive effects as well. Revealing secrets online can cause adolescents to feel relieved [Magsamen-Conrad, Billotte-Verhoff and Greene 2014]. The online disinhibition effect can also positively impact users who are shy [Amichai-Hamburger 2007; Saunders and Chester 2008], introverted, neurotic [Amichai-Hamburger, Wainapel and Fox 2002; Orchard and Fullwood 2010], socially phobic [Carlbring, Gunnarsdottir, Hedensjo, Ekselium and Furmark 2007], lonely [Whitty and McLaughlin 2007], have a stutter [Stoudt and Ouellette 2004], have impaired hearing [Barak and Sadovsky 2008], or are socially ostracized [McKenna and Seidman 2005; McKenna 2008] by making it easier for them in particular to share personal information.

If users are allowed to be \keyterm{anonymous}\index{anonymity} or \keyterm{pseudonymous}\index{pseudonymity} then they are significantly more likely to act out negatively [Lapidot-Lefler and Barak 2012]. This is why many online services connect your online identity with your real world identity, whether through your email address, phone number, or another social system login such as Facebook or Google. Even more online services establish norms\index{norm} of providing your real name and a picture of yourself, further merging your online and physical identities. By encouraging users to not be anonymous, online services such as Facebook, Instagram and Twitter promote a culture\index{culture} of positive interactions on their platforms.

However, it isn’t quite so black-and-white a case against anonymity. Depending on the service you are creating, anonymity may be beneficial or even necessary. Suppose you are creating a forum to talk about sensitive topics such as mental health and suicide ideation. Users may be unwilling to engage in these forums, thus depriving them of these resources, if they are not granted anonymity. Anonymity\index{anonymity} helps users open up more quickly to others about their personal struggles [Barak and Suler 2008; Suler 2008].

In short, whether to allow users to be anonymous isn’t a decision to be made lightly. Anonymity can lead to positive interactions, such as sharing mental health struggles, but it can easily lead to an influx of Internet trolls\index{troll}, which can greatly harm online communities.

\section{Intrinsic causes: psychology}

The horror-film franchise \textit{The Purge} explores what life would be like in a society in which all crime is legal for one day each year. In such a society, the film franchise argues, people would let out all their pent-up aggression during that one day, committing sadistic acts of torture and murder.

While this concept was taken to an extreme to make the film franchise interesting\footnote{If this society did actually exist, then there would probably be a few scattered acts of violence (primarily acts of vengeance or small-scale terrorism) but nothing near the scale suggested by the film franchise. More likely, there’d be a lot of theft, especially online theft (it’s safer than leaving your home). Imagine Black Friday but a thousand times worse. The software industry’s earnings would precipitate because nobody would want to buy software for the rest of the year when they can get it for free (and with a clear conscience) during Purge night.}, research indicates that there may be a grain of truth in it. There is a very strong correlation between \keyterm{GAIT}\index{GAIT score} (Global Assessment of Internet Trolling) scores and sadism, suggesting that trolls\index{troll} are typically more sadistic than non-trolls [Buckels et al. 2013; Buckels et al. 2014]. In fact, there is strong evidence that users troll online because it gives them sadistic pleasure [Buckels et al. 2014].

If you want to calculate your GAIT\index{GAIT score} score, it's pretty easy. In their 2014 study, Buckels et al. presented participants with the following four statements.

\begin{enumerate}
    \item "I have sent people to shock websites for the lulz."
    \item "I like to troll people in forums or the comments section of websites."
    \item "I enjoy griefing other players in multiplayer games."
    \item "The more beautiful and pure a thing is, the more satisfying it is to corrupt."\footnote{This statement is Rule 43 from \textit{Rules of the Internet} (http://rulesoftheinternet.com) and was included in the questionnaire to determine how closely the user identified with troll culture.}
\end{enumerate}

Participants rated their agreement with the four sentences on a 5-point scale, where 1 means "strongly disagree" and 5 means "strongly agree". A participant's GAIT\index{GAIT score} score is the mean of their ratings of these four sentences. Try calculating your GAIT score! For comparison, the mean GAIT score of an online commenter is 1.47, with a standard deviation of 0.78. If you have a GAIT score significantly above 1.47, then you just might be a troll!

Are trolls\index{troll} formed online? Or do they have a troll-ish personality before they even join online communities? Research has shown that there is a correlation between high levels of Internet use and antisocial behaviors [Carr 2011; Juvonen and Gross 2008; Phillips and Butt 2006; Rosen et al. 2013]. While some authors argue that engaging with the Internet causes users to become more antisocial [Carr 2011; Immordino-Yang, Christodoulou and Singh 2012; Suler 2004], there is insufficient evidence to definitely conclude that this is the case. It is possible that the reverse is the case, that people with already high levels of antisocial behavior tend to excessively use the Internet.

\section{Extrinsic causes: environment}

At the end of the day, we’re all human. We all have a good side as well as a bad side. Sometimes we get in bad moods and, when we do, we view others more negatively [Forgas and Bower 1987] and have a greater chance of losing self-control [Leith and Baumeister 1996]. This can cause us to lash out at others [Cheng et al. 2017].

This momentary hostile behavior is called \keyterm{flaming}\index{flaming}. [Kayany 1998; Kiesler 1986] Whereas trolling is often premeditated and deliberate, flaming is temporary and typically unplanned. Flaming usually consists of profanity and insults, often of a personal nature. It can often be identified by the overuse of capital letters, repeated punctuation and profanity [Turnage 2007].

Sometimes users will respond to flaming by flaming in turn. This is called a \keyterm{flame war}\index{flaming!flame war} and can draw in many users before it is broken up by moderators. Flame wars can destabilize communities and, consequently, flaming can result in suspensions from online forums. Their ability to disrupt communities has even been noticed by the U.S. State Department. In 2012, the State Department began investing in a project called \keyterm{Operation Viral Peace}\index{Operation Viral Peace}, which seeks to create flame wars\index{flaming!flame war} in jihadi online forums and thus disrupt their recruitment efforts [Sydiongco 2012, slate.com].

Many trolls\index{troll} seek to incite flaming\index{flaming} by deliberately posting offensive or controversial comments in order to provoke others into responding, known as “taking the bait”. This is called \keyterm{flamebaiting}\index{flaming!flamebaiting}. Many Internet users advise others to not respond, or “feed the trolls,” as doing so can lead to the trolls responding again and potentially lead to a flame war.\index{flaming!flame war}

--------------

The nature of trolls\index{troll}
\begin{itemize}
    \item They troll for various reasons: boredom [Varjas et al. 2010], because its fun [Shachaf and Hara 2010], to vent [Lee and Kim 2015]
    \item Time of day influences negative personality [Golder and Macy 2011]
    \item Mood influences behavior [Cheng et al. 2017]
    \item Trolling seems to worsen over time. [Cheng et al. 2017]
\end{itemize}

People self-regulate if they can do so without having to admit that they deliberately violated norms. [Kiesler et al. 2012]\\

\section{Free speech: protections and limitations}

Why is freedom of speech important? Many people spread falsehoods and actively malicious speech online, which is harmful. A common argument for freedom of speech is that good and truthful ideas will win out in the "marketplace of ideas". This idea comes from \textit{On Liberty}, a foundational political philosophy text by John Stuart Mill. In \textit{On Liberty}, Mill writes:

\begin{displayquote}
[T]he peculiar evil of silencing the expression of an opinion is, that it is robbing the human race; posterity as well as the existing generation; those who dissent from the opinion, still more than those who hold it. If the opinion is right, they are deprived of the opportunity of exchanging error for truth; if wrong, they lose, what is almost as great a benefit, the clearer perception and livelier impression of truth, produced by its collision with error. [Mill 1859]
\end{displayquote}

However, whether the marketplace of ideas really results in true ideas winning out is controversial. As philosophy professor Bryan Norden writes, "humans are not rational in the way Mill assumes." Norden argues that people do not all have the ability to take in competing claims and unfailingly determine which claim is true. If that were true, Norden argues, then there wouldn't be disagreement about certain truths, such as the mere existence of a mass shooting in Sandy Hook, yet radio talk show host Alex Jones is known for arguing that the mass shooting was staged. [Norden 2018]

In the United States, the \keyterm{First Amendment} protects nearly all forms of speech, including speech online [Reno v. ACLU 1997].\footnote{There are a few exceptions. For example, the First Amendment does not protect speech that poses harm to others or speech that is obscene.} Many online trolls\index{troll} take advantage of this protection to justify spreading racist, misogynistic and other hateful remarks on the Internet.\index{free speech}

However, also under the First Amendment\index{free speech}, other people have the right to \textit{not} sell products to these trolls. Under federal law, they can't deny customers arbitrarily or violate discrimination laws.\index{discrimination}\footnote{Under federal law (the Civil Rights Act of 1964 and the Americans with Disabilities Act), public businesses can't deny customers on the basis of race, color, religion, national origin, sex or disability. Many states have additional anti-discrimination laws prohibiting discrimination on bases such as age, veteran status, marital status, pregnancy, sexual orientation, gender identity, medical conditions, personal appearance and political beliefs. However, which additional classes are protected vary by state.} They are therefore able to deny customers if they provide a reason for doing so that applies equally to everybody and doesn't violate anti-discrimination laws [Haskins 2015]. Consequently, Internet Service Providers (ISPs), search engines and social media websites can deny service to people who violate their \keyterm{Terms of Service}\index{Terms of Service}. Some non-governmental organizations such as the Anti-Defamation League and the Southern Poverty Law Center work to inform these Internet services of instances of trolls violating their Terms of Service so that they can take action against the trolls [Henry 2009].\index{free speech}

While these efforts are very successful in the fight against online trolls\index{troll}, they are not perfect. Non-governmental organizations can inform ISPs about hateful content; however, whether the ISP chooses to remove the content is ultimately up to them. Under Section 230 of the Communications Decency Act, ISPs are not liable for any hateful content on websites they host. In addition, some extremists have organized their own ISPs, such as Stormfront, which work to host hateful websites that other ISPs deny service to. [Henry 2009]\index{free speech}

\textbf{TODO: Check to make sure that Stormfront is actually the name of the ISP -- might not be}

\section{Reading questions}

\begin{enumerate}
    \item Suppose you want to calculate your friend's GAIT score. He rates the four statements with scores of 1, 4, 3 and 2 respectively.
    \begin{enumerate}
        \item What is your friend's GAIT score?
        \item Is your friend's GAIT score within one standard deviation (0.78) of the mean GAIT score (1.47)?
    \end{enumerate}
\end{enumerate}

\section{Solutions to reading questions}

\section{Bibliography}

Bernstein, Michael et al. "4chan and /b/: An Analysis of Anonymity and Ephemerality in a Large Online Community." ICWSM 2011: AAAI Conference on Weblogs and Social Media." 2011.

Buckel et al. "Behavioral confirmation of everyday sadism." Psychological Science. 24:2201-2209. 2013. Web.

Buckels et al. "Trolls just want to have fun." Personality and Individual Differences. 67:97-102. February, 2014. Web.

Carr. \textit{The shallows: What the Internet is doing to our brains.} New York, NY: W.W. Norton \& Company.

Cheng, Justin et al. "Anyone Can Become a Troll: Causes of Trolling Behavior in Online Discussions." CSCW: Conf Comput Support Coop Work. 2017:1217-1230. 2017. Web.

Cole, Kirsti K. "'It's Like She's Eager to be Verbally Abused': Twitter, Trolls, and (En)Gendering Disciplinary Rhetoric." Feminist Media Studies 15 (2): pp. 356-358. February 13, 2015.

ElSherief, Mai et al. "Hate Lingo: A Target-Based Linguistic Analysis of Hate Speech in Social Media." Twelfth International AAAI Conference on Web and Social Media. June 15, 2018.

Haskins, Jane. Esq. "The Right to Refuse Service: Can a Business Refuse Service to Someone?" Legalzoom. April 6, 2015.

Henry, Jessica S. "Beyond free speech: novel approaches to hate on the Internet in the United States." Information \& Communications Technology Law 18 (2): pp. 235-251. June 19, 2009.

Immordino-Yang et al. "Rest is not idleness: Implications of the brain's default mode for human development and education." Perspectives on Psychoogical Science. 7:352-364. 2012. Web.

Juvonen and Gross. "Extending the school grounds? Bullying experiences in cyberspace." Journal of School Health. 78:496-505. 2008. Web.

Mill, John Stuart. \textit{On Liberty}

Norden, Bryan W. Van. "The Ignorant Do Not Have a Right to an Audience." The New York Times. June 25, 2018.

Philips and Butt. "Personality and self-reported used of mobile phones for games." CyberPsychology \& Behavior. 9:753-758. 2006. Web.

Phillips, Whitney. "LOLing at tragedy: Facebook trolls, memorial pages and resistance to grief online." First Monday 16 (12). December 5, 2011.

Reno v. ACLU. pp. 868-870. 1997.

Rosen et al. "Is Facebook creating 'Disorders?' The link between clinical symptoms of psychiatric disorders and technology use, attitudes and anxiety." Computers in Human Behavior. 29:1243-1254. 2013. Web.

Suler, John. "The Online Disinhibition Effect." CyberPsychology \& Behavior. 7(3):321-6. July 2004. Web.

Sydiongco, David. "New Strategy in the War on Terror: Trolling Jihadi Forums." Slate. July 19, 2012. Web.

Turnage, Anna K. "Email Flaming Behaviors and Organizational Conflict." Journal of Computer-Mediated Communication. 13(1). December 17, 2007. Web.

Turton-Turner, Pamela. "Villainous avatars: the visual semiotics of misogyny and free speech in cyberspace." Forum on Public Policy: A Journal of the Oxford Round Table." Gale Academic Onefile. 2013.

\section{Image credits}

\end{document}
