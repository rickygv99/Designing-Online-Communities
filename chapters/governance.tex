\documentclass[class=book, crop=false]{standalone}

%% Image paths
\usepackage{graphicx}
\graphicspath{{images/}}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}

%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

%% Sets epigraph style
\usepackage{epigraph}
\setlength\epigraphwidth{.8\textwidth}
\setlength\epigraphrule{0pt}

%% Sets line style
\linespread{1.3}

%% Key term command
\usepackage{marginnote}
\providecommand{\keyterm}[1]{\textbf{#1}\marginnote{\scriptsize \textbf{#1}}}

\begin{document}

Moderators\index{moderation} themselves usually don't make the decisions that determine what policies to enforce and what type of content to allow on their platforms. So who does make the decisions? Typically, the line determining what content is permissible has been very blurry. Social systems strive to balance free speech\index{free speech} and a safe environment but tend to be inconsistent in deciding what is allowed and what isn't. What one moderator might feel is acceptable another might feel violates their policies. This inconsistency has led to allegations of bias and discrimination against many tech companies, including Facebook, Twitter and Google.\index{discrimination}

\section{Autocracy and technocracy}

\subsection{Implicit feudalism}

implicit feudalism [Schneider, Nathan and Calvin Liu 2019]

\section{Facebook's Oversight Board}

In 2019, Facebook began developing an Oversight Board\index{Facebook!Oversight Board}, which will have the final say in any controversial moderation decisions and will even be able to reverse the decisions of moderators. The board will be independent from Facebook (thus protecting Facebook from accusations of bias) and, in the interest of transparency, the board's decision making process, final decisions, and list of members will all be known to the public. [Clegg 2019, Facebook]\\

\section{Ostrom workshop}

\subsection{Participatory change}

participatory change [Frey, Seth et al. 2019]

\section{Modular politics}

modular politics [De Filippi, Primavera et al.]

\section{Decision resolution}

resolution [Im, Jane et al. 2018]

\section{Digital juries}

digital juries [Fan, Jenny and Amy Zhang 2020]

\section{Reading questions}

\section{Solutions to reading questions}

\section{Bibliography}

Clegg, Nick. "Charting a Course for an Oversight Board for Content Decisions." Facebook. January 28, 2019.

De Filippi, Primavera et al. "Modular Politics: Toward a Governance Layer for Online Communities."

Fan, Jenny and Amy X. Zhang. "Digital Juries: A Civics-Oriented Approach to Platform Governance." CHI 2020, April 25-30, 2020.

Frey, Seth et al. "'This Place Does What It Was Built For': Designing Digital Institutions for Participatory Change." Proceedings of the ACM on Human-Computer Interaction. 32. November, 2019.

Im, Jane et al. "Deliberation and Resolution on Wikipedia: A Case Study of Requests for Comments." In Proceedings of the ACM on Human-Computer Interaction, Vol. 2, CSCW, Article 74. November, 2018.

Schneider, Nathan and Calvin Liu. "Admins, Mods, and Benevolent Dictators for Life: The Implicit Feudalism of Online Communities." 2019.

\end{document}
